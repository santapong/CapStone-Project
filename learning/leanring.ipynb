{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is an open-source project that aims to provide a universal interface for interacting with web3 data and smart contracts, allowing developers to build applications that seamlessly connect to various blockchain networks.\\n\\nTo better understand LangChain, let's break it down into its core components:\\n\\n1. **LangChain Core**: This is the foundation of the platform, which provides a set of libraries and tools for interacting with web3 data and smart contracts. It includes modules for working with NFTs, tokens, and more.\\n2. **LangChain Bridge**: This component enables seamless interaction between different blockchain networks, allowing developers to build decentralized applications (dApps) that work across multiple chains.\\n3. **LangChain SDKs**: LangChain provides software development kits (SDKs) for popular programming languages like Rust, JavaScript, and Python, making it easier for developers to integrate the platform into their existing projects.\\n4. **LangChain CLI**: The command-line interface (CLI) allows users to interact with LangChain directly from the terminal, making it easy to manage and deploy smart contracts, NFTs, and other web3 assets.\\n\\nBy providing a unified interface for interacting with web3 data and smart contracts, LangChain aims to simplify the development process for decentralized applications and make it more accessible to a wider range of developers.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
